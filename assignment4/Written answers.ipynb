{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__g) The `generate_sent_masks()` function in `nmt_model.py` produces a tensor called `enc_masks`. It has shape (batch size, max source sentence length) and contains 1s in positions corresponding to ‘pad’ tokens in the input, and 0s for non-pad tokens. Look at how the masks are used during the attention computation in the `step()` function (lines 295-296). First explain (in around three sentences) what effect the masks have on the entire attention computation. Then explain (in one or two sentences) why it is necessary to use the masks in this\n",
    "way.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We assign $-\\infty$ to every attention score with a mask's value 1 (pad-tokens). After that we use softmax to obtain distribution of attention. And `softmax(-Inf) == 0`, so we don't pay any attention to pad-tokens at all.\n",
    "It's necessary because pad-tokens doesn't exist in fact and were used just to make the shape of our data correct. We don't want them to influence on results of any part of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__i) Please report the model’s corpus BLEU Score. It should be larger than 21.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "```\n",
    "Corpus BLEU: 22.34060291466605\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__j) In class, we learned about dot product attention, multiplicative attention, and additive\n",
    "attention. Please provide one possible advantage and disadvantage of each attention mechanism,\n",
    "with respect to either of the other two attention mechanisms. As a reminder, dot product attention\n",
    "is $e_{t,i} = s^T_t h_i$ , multiplicative attention is $e_{t,i} = s^T_t Wh_i$, and additive attention is $e_{t,i} = v^T (W_1 h_i +\n",
    "W_2 s_t)$.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We increase flexibility of our attention mechanism when moving from dot product attention to multiplicative attention to additive attention. However we also increase complexity of our model and number of trainable weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing NMT Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a) Here we present a series of errors we found in the outputs of our NMT model (which is the same as the one you just trained). For each example of a Spanish source sentence, reference (i.e., ‘gold’) English translation, and NMT (i.e., ‘model’) English translation, please:__\n",
    "\n",
    "__1. Identify the error in the NMT translation.__\n",
    "\n",
    "__2. Provide a reason why the model may have made the error (either due to a specific linguistic construct or specific model limitations).__\n",
    "\n",
    "__3. Describe one possible way we might alter the NMT system to fix the observed error.__\n",
    "\n",
    "__Below are the translations that you should analyze as described above. Note that out-of-vocabulary words are underlined.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.\n",
    "\n",
    "Source Sentence: Aquı́ otro de mis favoritos, “La noche estrellada”.\n",
    "\n",
    "Reference Translation: So another one of my favorites, “The Starry Night”.\n",
    "\n",
    "NMT Translation: Here’s another favorite of my favorites, “The Starry Night”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "Repeating word \"favorite\". Maybe it's not common in spanish to use word \"one\" in such context. We can provide more examples of translation of such phrase in a training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.\n",
    "\n",
    "Source Sentence: Ustedes saben que lo que yo hago es escribir para los niños, y,\n",
    "de hecho, probablemente soy el autor para niños, ms ledo en los EEUU.\n",
    "\n",
    "Reference Translation: You know, what I do is write for children, and I’m probably America’s\n",
    "most widely read children’s author, in fact.\n",
    "\n",
    "NMT Translation: You know what I do is write for children, and in fact, I’m probably the\n",
    "author for children, more reading in the U.S.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We repeat the same phrase \"for children\" twice. Maybe we can teach our algorithm to use synonymical phrases more often. I.e. \"I write for children\" and \"I'm the author for children\" have the same meaning but make sentence more readable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.\n",
    "\n",
    "Source Sentence: Un amigo me hizo eso – Richard Bolingbroke.\n",
    "\n",
    "Reference Translation: A friend of mine did that – Richard Bolingbroke.\n",
    "\n",
    "NMT Translation: A friend of mine did that – Richard (unk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We were unable to found translation for a surname \"Bolingbroke\". Obviously it doesn't appear in our vocabulary of target language. We can try to add it, or come with some way to exclude names from our typical flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.\n",
    "\n",
    "Source Sentence: Solo tienes que dar vuelta a la manzana para verlo como una epifanı́a.\n",
    "\n",
    "Reference Translation: You’ve just got to go around the block to see it as an epiphany.\n",
    "\n",
    "NMT Translation: You just have to go back to the apple to see it as a epiphany."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Looks like word \"manzana\" has two distinct meanings in Spanish: apple and block. Our model was unable to choose the correct one. Maybe we can fix it if we train our word embeddings in a way which make distinction more obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.\n",
    "\n",
    "Source Sentence: Ella salvó mi vida al permitirme entrar al baño de la sala de profesores.\n",
    "\n",
    "Reference Translation: She saved my life by letting me go to the bathroom in the teachers’ lounge.\n",
    "\n",
    "NMT Translation: She saved my life by letting me go to the bathroom in the women’s room."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We totally lost information about \"teachers' lounge\". Maybe it's due to too high attention to word \"She\". We can try to use more complex attention mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.\n",
    "\n",
    "Source Sentence: Eso es más de 100,000 hectáreas.\n",
    "\n",
    "Reference Translation: That’s more than 250 thousand acres.\n",
    "\n",
    "NMT Translation: That’s over 100,000 acres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Reference translation includes transformation from metric hectars to non-metric acres, more common in English. In fact it's a problem of reference translation. We can include more examples of usage of word \"hectar\" in our English training set and get correct translation \"100,000\" hectars\". Making a model to translate one units to another is too complicated and absolutel not necessary (if not harmful)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Now it is time to explore the outputs of the model that you have trained! The test-set translations your model produced in question 1-i should be located in outputs/test outputs.txt. Please identify 2 examples of errors that your model produced. 2 The two examples you find should be different error types from one another and different error types than the examples provided in the previous question.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "i. \n",
    "\n",
    "Source Sentence: Yo estaba asombrada.\n",
    "\n",
    "Reference Translation: I was in awe.\n",
    "\n",
    "NMT Translation: I was (unk)\n",
    "\n",
    "Looks like word \"awe\" is too uncommon in English and is not in a vocabulary, so we were unable to translate it. We can't expand our vocabulary and corpus.\n",
    "\n",
    "ii.\n",
    "\n",
    "Source Sentence: Y estamos observando esto en todos los mbitos de la vida humana.\n",
    "\n",
    "Reference Translation: So we're seeing this  in all sorts of places in human life.\n",
    "\n",
    "NMT Translation: And we're looking at this in all the spheres of human life.\n",
    "\n",
    "Word \"looking\" is not right in this context. Maybe if we include some POS-data or grammatical rules in our embeddings than we'll be able to deal with this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c) Please consider this example:__\n",
    "\n",
    "Source Sentence $s$: el amor todo lo puede\n",
    "\n",
    "Reference Translation $r_1$: love can always find a way\n",
    "\n",
    "Reference Translation $r_2$: love makes anything possible\n",
    "\n",
    "NMT Translation $c_1$: the love can always do\n",
    "\n",
    "NMT Translation $c_2$: love can make anything possible\n",
    "\n",
    "__Please compute the BLEU scores for $c_1$ and $c_2$. Let $\\lambda_i = 0.5$ for $i \\in {1, 2}$ and $\\lambda_i = 0$ for $i \\in {3, 4}$ (this means we ignore 3-grams and 4-grams, i.e., don’t compute $p_3$ or $p_4$). When computing BLEU scores, show your working (i.e., show your computed values for $p_1$, $p_2$, $c$, $r^∗$ and $BP$). Which of the two NMT translations is considered the better translation according to the BLEU Score? Do you agree that it is the better translation?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "i.\n",
    "\n",
    "For $c_1$:\n",
    "\n",
    "| 1-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| the | 1 | 0 | 0 | 0 | 0 |\n",
    "| love | 1 | 1 | 1 | 1 | 1 |\n",
    "| can | 1 | 1 | 0 | 1 | 1 |\n",
    "| always | 1 | 1 | 0 | 1 | 1 |\n",
    "| do | 1 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "$p_1 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 1-grams}} = \\frac 3 5 = 0.6$\n",
    "\n",
    "| 2-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| the love | 1 | 0 | 0 | 0 | 0 |\n",
    "| love can | 1 | 1 | 0 | 1 | 1 |\n",
    "| can always | 1 | 1 | 0 | 1 | 1 |\n",
    "| always do | 1 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "$p_2 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 2-grams}} = \\frac 2 4 = 0.5$\n",
    "\n",
    "$r_1$ is more similar to $c_1$, so $r^* = 6$. ${BP} = \\exp (1 - \\frac {r^*} {c}) = \\exp(-0.2) \\approx 0.8187$\n",
    "\n",
    "${BLEU}_{c_1} = {BP} \\times \\exp(\\sum_n {\\lambda_n \\log{p_n}}) = 0.8187 * \\exp(0.5*\\log 0.6 + 0.5*\\log 0.5) \\approx 0.4484$ \n",
    "\n",
    "For $c_2$:\n",
    "\n",
    "| 1-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| love | 1 | 1 | 1 | 1 | 1 |\n",
    "| can | 1 | 1 | 0 | 1 | 1 |\n",
    "| make | 1 | 0 | 1 | 1 | 1 |\n",
    "| anything | 1 | 0 | 1 | 1 | 1 |\n",
    "| possible | 1 | 0 | 1 | 1 | 1 |\n",
    "\n",
    "$p_1 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 1-grams}} = \\frac 5 5 = 1.0$\n",
    "\n",
    "| 2-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| love can | 1 | 1 | 0 | 1 | 1 |\n",
    "| can make | 1 | 0 | 0 | 0 | 0 |\n",
    "| make anything | 1 | 0 | 1 | 1 | 1 |\n",
    "| anything possible | 1 | 0 | 1 | 1 | 1 |\n",
    "\n",
    "$p_2 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 2-grams}} = \\frac 3 4 = 0.75$\n",
    "\n",
    "$r_2$ is more similar to $c_2$, so $r^* = 4$. ${BP} = 1.0$\n",
    "\n",
    "${BLEU}_{c_2} = {BP} \\times \\exp(\\sum_n {\\lambda_n \\log{p_n}}) = 1.0 * \\exp(0.5*\\log 1.0 + 0.5*\\log 0.75) \\approx 0.866$ \n",
    "\n",
    "So we have ${BLEU}_{c_1} \\approx 0.4484$ and ${BLEU}_{c_2} \\approx 0.866$. The second translation is better in terms of BLEU score and I can agree that it is a better transaltion then the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.\n",
    "\n",
    "In case of presence of only $r_1$.\n",
    "\n",
    "For $c_1$:\n",
    "\n",
    "| 1-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| the | 1 | 0 | NA | 0 | 0 |\n",
    "| love | 1 | 1 | NA | 1 | 1 |\n",
    "| can | 1 | 1 | NA | 1 | 1 |\n",
    "| always | 1 | 1 | NA | 1 | 1 |\n",
    "| do | 1 | 0 | NA | 0 | 0 |\n",
    "\n",
    "$p_1 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 1-grams}} = \\frac 3 5 = 0.6$\n",
    "\n",
    "| 2-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| the love | 1 | 0 | NA | 0 | 0 |\n",
    "| love can | 1 | 1 | NA | 1 | 1 |\n",
    "| can always | 1 | 1 | NA | 1 | 1 |\n",
    "| always do | 1 | 0 | NA | 0 | 0 |\n",
    "\n",
    "$p_2 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 2-grams}} = \\frac 2 4 = 0.5$\n",
    "\n",
    "$r_1$ is more similar to $c_1$, so $r^* = 6$. ${BP} = \\exp (1 - \\frac {r^*} {c}) = \\exp(-0.2) \\approx 0.8187$\n",
    "\n",
    "${BLEU}_{c_1} = {BP} \\times \\exp(\\sum_n {\\lambda_n \\log{p_n}}) = 0.8187 * \\exp(0.5*\\log 0.6 + 0.5*\\log 0.5) \\approx 0.4484$ \n",
    "\n",
    "For $c_2$:\n",
    "\n",
    "| 1-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| love | 1 | 1 | NA | 1 | 1 |\n",
    "| can | 1 | 1 | NA | 1 | 1 |\n",
    "| make | 1 | 0 | NA | 0 | 0 |\n",
    "| anything | 1 | 0 | NA | 0 | 0 |\n",
    "| possible | 1 | 0 | NA | 0 | 0 |\n",
    "\n",
    "$p_1 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 1-grams}} = \\frac 2 5 = 0.4$\n",
    "\n",
    "| 2-gram | ${Count}_c$ | ${Count}_{r_1}$ | ${Count}_{r_2}$ | ${max}({Count}_{r_1}, {Count}_{r_2})$ | $\\text{numerator term}$ |\n",
    "| - | - | - | - | - | - |\n",
    "| love can | 1 | 1 | NA | 1 | 1 |\n",
    "| can make | 1 | 0 | NA | 0 | 0 |\n",
    "| make anything | 1 | 0 | NA | 0 | 0 |\n",
    "| anything possible | 1 | 0 | NA | 0 | 0 |\n",
    "\n",
    "$p_2 = \\frac {\\sum {\\text {numerator term}}} {\\text {Num of 2-grams}} = \\frac 1 4 = 0.25$\n",
    "\n",
    "$r_2$ is more similar to $c_2$ but is not present. So we must use $r_1$, so $r^* = 6$. ${BP} \\approx 0.8187$\n",
    "\n",
    "${BLEU}_{c_2} = {BP} \\times \\exp(\\sum_n {\\lambda_n \\log{p_n}}) = 0.8187 * \\exp(0.5*\\log 0.4 + 0.5*\\log 0.25) \\approx 0.2589$ \n",
    "\n",
    "So we have the same ${BLEU}_{c_1} \\approx 0.4484$ and much lower ${BLEU}_{c_2} \\approx 0.2589$. The first translation is much better in terms of BLEU score now. But it's not that good as the second one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.\n",
    "\n",
    "The only available reference translation can strongly shift BLEU results as we've seen above. Good enough translations can be scored very low if they consist from different words comparing with reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.\n",
    "\n",
    "Advantages of BLEU:\n",
    "* it can be computed automatically and be used as a part of model's validation \n",
    "* it shows rather good results in case of multiple reference translations\n",
    "* it can be interpreted as a measure of goodness\n",
    "\n",
    "Disadvantages of BLEU:\n",
    "* we need to get good corpus of reference translations\n",
    "* it becomes biased in case of too few reference translations\n",
    "* it can behave bad in languages which allow more freedom in a sequence of words without changing the meaning - in this case n-gram measurements can underestimate similarity between translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
